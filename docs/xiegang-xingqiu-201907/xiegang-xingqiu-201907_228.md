# 分享一份 Pyth

# 分享一份 Pyth

小猿 : 分享一份 Python 爬虫：入门+进阶 的学习路线，有兴趣 的同学，可以按着这个 Python 爬虫大纲，一步一步深入学习！ 喜欢的还是不忘记点个赞哈！ 第一章：Python 爬虫入门 1、 什么是爬虫 网址构成和翻页机制 网页源码结构及网页请求过 程 爬虫的应用及基本原理 2、初识 Python 爬虫 Python 爬虫环 境搭建 创建第一个爬虫：爬取百度首页 爬虫三步骤：获取数 据、解析数据、保存数据 3、使用 Requests 爬取豆瓣短评 Requests 的安装和基本用法 用 Requests 爬取豆瓣短评信息 一 定要知道的爬虫协议 4、使用 Xpath 解析豆瓣短评 解析神器 Xpath 的安装及介绍 Xpath 的使用：浏览器复制和手写 实战： 用 Xpath 解析豆瓣短评信息 5、使用 pandas 保存豆瓣短评数据 pandas 的基本用法介绍 pandas 文件保存、数据处理 实战：使 用 pandas 保存豆瓣短评数据 6、浏览器抓包及 headers 设置（案 例一：爬取知乎） 爬虫的一般思路：抓取、解析、存储 浏览 器抓包获取 Ajax 加载的数据 设置 headers 突破反爬虫限制 实 战：爬取知乎用户数据 7、数据入库之 MongoDB（案例二： 爬取拉勾） MongoDB 及 RoboMongo 的安装和使用 设置等待 时间和修改信息头 实战：爬取拉勾职位数据 将数据存储在 MongoDB 中 补充实战：爬取微博移动端数据 8、Selenium 爬 取动态网页（案例三：爬取淘宝） 动态网页爬取神器 Selenium 搭建与使用 分析淘宝商品页面动态信息 实战：用 Selenium 爬取淘宝网页信息 第二章：Python 爬虫之 Scrapy 框架 1、爬虫工程化及 Scrapy 框架初窥 html、css、js、数据库、http 协议、前后台联动 爬虫进阶的工作流程 Scrapy 组件：引擎、 调度器、下载中间件、项目管道等 常用的爬虫工具：各种数 据库、抓包工具等 2、Scrapy 安装及基本使用 Scrapy 安装 Scrapy 的基本方法和属性 开始第一个 Scrapy 项目 3、Scrapy 选 择器的用法 常用选择器：css、xpath、re、pyquery css 的使用 方法 xpath 的使用方法 re 的使用方法 pyquery 的使用方法 4、

Scrapy 的项目管道 Item Pipeline 的介绍和作用 Item Pipeline 的主 要函数 实战举例：将数据写入文件 实战举例：在管道里过滤 数据 5、Scrapy 的中间件 下载中间件和蜘蛛中间件 下载中间 件的三大函数 系统默认提供的中间件 6、Scrapy 的 Request 和 Response 详解 Request 对象基础参数和高级参数 Request 对象方 法 Response 对象参数和方法 Response 对象方法的综合利用详 解 第三章：Python 爬虫进阶操作 1、网络进阶之谷歌浏览器 抓包分析 http 请求详细分析 网络面板结构 过滤请求的关键字 方法 复制、保存和清除网络信息 查看资源发起者和依赖关系 2、数据入库之去重与数据库 数据去重 数据入库 MongoDB 第 四章：分布式爬虫及实训项目 大规模并发采集——分布式爬 虫的编写 分布式爬虫介绍 Scrapy 分布式爬取原理 Scrapy-Redis 的使用 Scrapy 分布式部署详解

2018-03-22

关注公众号"懒人找资源"，星球资源一站式服务